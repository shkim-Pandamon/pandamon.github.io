---
title: "Research Reviews"
excerpt: "reviews"

tages:
    - Reviews
last_modified_at: 2001-01-01T19:25:00
---

Belows are my reviews of several technologies about `Machine Learning`, `AI`, and etc. They could be from research papers, or blog posts. Early period of my graduate student life, I just read articles, highlighted some sentences, saved in on EndNote and, totally forgot everything. And one day, I realized that these could be very volatile, and I cannot remember any knowledge that I studied before. Since then, I tried remaining concise notes that describes the content of that I studied. But still it is not enough to remain the knowledge. Yes, the problem was that I just skim the concepts of it, but did not really 'learn' it and make it as mine. It should be based on 'experience'.  

That is why I begin this reviews. Here, I would try to remain the knowledge in my words and study some toy examples with logs on `GitHub`. Also, I am gonna try to study densely, which means if I do not clearly understand the basis, I would go back to elemental study first and come back to target articles.  

Glad to share my experience. 

> - The order of list is inversely along to the date that I wrote the reviews.
> - [date_of_original_material] name_of_original_material

--------

<details>
<summary><span style="color:black"><strong>Google AI Blog</strong></span></summary>
<div markdown="1">

- [Mar 25. 2021] [Constructing Transformers For Longer Sequences with Sparse Attention Methods]({{variables.base_url}}/reviews/review_1/). ([original_text](https://ai.googleblog.com/2021/03/constructing-transformers-for-longer.html))
- [Mar 25. 2021] [Constructing Transformers For Longer Sequences with Sparse Attention Methods]({{variables.base_url}}/reviews/review_1/). ([original_text](https://ai.googleblog.com/2021/03/constructing-transformers-for-longer.html))
- [Mar 25. 2021] [Constructing Transformers For Longer Sequences with Sparse Attention Methods]({{variables.base_url}}/reviews/review_1/). ([original_text](https://ai.googleblog.com/2021/03/constructing-transformers-for-longer.html))


</div>
</details>